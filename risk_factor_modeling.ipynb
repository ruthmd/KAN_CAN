{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebedd866",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optax yfinance lxml plotly hmmlearn \"jax[cuda12]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923ed9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, vmap, jit\n",
    "import numpy as np\n",
    "import optax\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple, Callable, Any\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "# Define the KAN Layer for risk factor modeling\n",
    "# Fix for the KANLayer class - changing the conditional activation initialization\n",
    "class KANLayer:\n",
    "    def __init__(self, input_dim: int, output_dim: int, num_basis: int = 30, \n",
    "                 domain=(-3.0, 3.0), key=None):\n",
    "        \"\"\"Initialize a KAN layer with learnable activation functions.\n",
    "        \n",
    "        Args:\n",
    "            input_dim: Input dimension\n",
    "            output_dim: Output dimension\n",
    "            num_basis: Number of basis functions for learned activation\n",
    "            domain: Domain over which the activation functions are defined\n",
    "            key: JAX random key\n",
    "        \"\"\"\n",
    "        if key is None:\n",
    "            key = jax.random.PRNGKey(0)\n",
    "        \n",
    "        key1, key2, key3 = jax.random.split(key, 3)\n",
    "        \n",
    "        # Initialize weights for linear transformation\n",
    "        self.weights = jax.random.normal(key1, (input_dim, output_dim)) * 0.1\n",
    "        \n",
    "        # Initialize biases\n",
    "        self.biases = jax.random.normal(key2, (output_dim,)) * 0.01\n",
    "        \n",
    "        # Grid points for activation function representation\n",
    "        self.grid_points = jnp.linspace(domain[0], domain[1], num_basis)\n",
    "        \n",
    "        # Initialize activation function values with different shapes\n",
    "        # For risk factor modeling, we want a variety of shapes to capture different risk relationships\n",
    "        activations_list = []\n",
    "        for i in range(output_dim):\n",
    "            subkey = jax.random.fold_in(key3, i)\n",
    "            # Use vmap and switch instead of if-else\n",
    "            init_type = jax.random.randint(subkey, (), 0, 4)\n",
    "            \n",
    "            # Define all possible activations\n",
    "            linear_act = self.grid_points\n",
    "            relu_act = jnp.maximum(0, self.grid_points)\n",
    "            sigmoid_act = 1.0 / (1.0 + jnp.exp(-self.grid_points))\n",
    "            tanh_act = jnp.tanh(self.grid_points)\n",
    "            \n",
    "            # Use select_n (JAX's functional switch) to choose activation\n",
    "            act = jnp.select(\n",
    "                jnp.array([init_type == 0, init_type == 1, init_type == 2, init_type == 3]),\n",
    "                jnp.array([linear_act, relu_act, sigmoid_act, tanh_act]),\n",
    "                self.grid_points  # default value\n",
    "            )\n",
    "            \n",
    "            # Add noise to break symmetry (still using the same subkey)\n",
    "            noise = jax.random.normal(subkey, (num_basis,)) * 0.05\n",
    "            act = act + noise\n",
    "            activations_list.append(act)\n",
    "        \n",
    "        # Stack into a matrix: (output_dim, num_basis)\n",
    "        self.activations = jnp.stack(activations_list)\n",
    "        \n",
    "        # Store domain for clipping\n",
    "        self.domain = domain\n",
    "    \n",
    "    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        \"\"\"Forward pass through the KAN layer.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, input_dim)\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor of shape (batch_size, output_dim)\n",
    "        \"\"\"\n",
    "        # Linear transformation\n",
    "        z = jnp.dot(x, self.weights) + self.biases  # Shape: (batch_size, output_dim)\n",
    "        \n",
    "        # Apply learned activation functions by interpolation\n",
    "        z_clipped = jnp.clip(z, self.domain[0], self.domain[1])\n",
    "        \n",
    "        # Fix the apply_activation function as well to avoid control flow issues\n",
    "        def apply_activation(z_i, i):\n",
    "            \"\"\"Apply the i-th activation function to z_i using linear interpolation.\"\"\"\n",
    "            idx = jnp.searchsorted(self.grid_points, z_i) - 1\n",
    "            idx = jnp.clip(idx, 0, len(self.grid_points) - 2)\n",
    "            \n",
    "            x0 = jnp.take(self.grid_points, idx)\n",
    "            x1 = jnp.take(self.grid_points, idx + 1)\n",
    "            y0 = jnp.take(self.activations[i], idx)\n",
    "            y1 = jnp.take(self.activations[i], idx + 1)\n",
    "            \n",
    "            t = (z_i - x0) / (x1 - x0)\n",
    "            return y0 + t * (y1 - y0)\n",
    "        \n",
    "        # Apply activation function for each element in the batch and each output dimension\n",
    "        output = jnp.zeros_like(z)\n",
    "        for i in range(z.shape[1]):  # For each output dimension\n",
    "            output = output.at[:, i].set(vmap(lambda z_i: apply_activation(z_i, i))(z[:, i]))\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Full KAN model for risk factor decomposition\n",
    "class RiskFactorKAN:\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dims: List[int] = [64, 32], \n",
    "                 num_basis: int = 30, domain=(-3.0, 3.0), key=None):\n",
    "        \"\"\"Initialize a KAN model for risk factor decomposition.\n",
    "        \n",
    "        Args:\n",
    "            input_dim: Input dimension (market factors)\n",
    "            output_dim: Output dimension (portfolio or asset returns)\n",
    "            hidden_dims: List of hidden dimensions\n",
    "            num_basis: Number of basis functions for learned activations\n",
    "            domain: Domain for activation functions\n",
    "            key: JAX random key\n",
    "        \"\"\"\n",
    "        if key is None:\n",
    "            key = jax.random.PRNGKey(0)\n",
    "        \n",
    "        keys = jax.random.split(key, len(hidden_dims) + 1)\n",
    "        \n",
    "        # Initialize layers\n",
    "        self.layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layer = KANLayer(prev_dim, hidden_dim, num_basis, domain, keys[i])\n",
    "            self.layers.append(layer)\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Final layer for risk factor outputs\n",
    "        self.output_layer = KANLayer(prev_dim, output_dim, num_basis, domain, keys[-1])\n",
    "    \n",
    "    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        \"\"\"Forward pass through the KAN model.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, input_dim)\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor of shape (batch_size, output_dim) representing asset returns\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Apply output layer\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "    @property\n",
    "    def params(self):\n",
    "        \"\"\"Get model parameters as a flat dictionary.\"\"\"\n",
    "        params = {}\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            params[f'layer_{i}_weights'] = layer.weights\n",
    "            params[f'layer_{i}_biases'] = layer.biases\n",
    "            params[f'layer_{i}_activations'] = layer.activations\n",
    "        \n",
    "        params['output_layer_weights'] = self.output_layer.weights\n",
    "        params['output_layer_biases'] = self.output_layer.biases\n",
    "        params['output_layer_activations'] = self.output_layer.activations\n",
    "        \n",
    "        return params\n",
    "    \n",
    "    def update_params(self, params):\n",
    "        \"\"\"Update model parameters from a flat dictionary.\"\"\"\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            layer.weights = params[f'layer_{i}_weights']\n",
    "            layer.biases = params[f'layer_{i}_biases']\n",
    "            layer.activations = params[f'layer_{i}_activations']\n",
    "        \n",
    "        self.output_layer.weights = params['output_layer_weights']\n",
    "        self.output_layer.biases = params['output_layer_biases']\n",
    "        self.output_layer.activations = params['output_layer_activations']\n",
    "\n",
    "# Generate synthetic market data for training\n",
    "def generate_risk_factor_data(num_samples=20000, num_risk_factors=5, num_assets=20, seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic market data for risk factor decomposition.\n",
    "    \n",
    "    Args:\n",
    "        num_samples: Number of time periods (e.g., days)\n",
    "        num_risk_factors: Number of underlying risk factors\n",
    "        num_assets: Number of assets in the portfolio\n",
    "        seed: Random seed\n",
    "        \n",
    "    Returns:\n",
    "        factor_returns: Risk factor returns\n",
    "        asset_returns: Asset returns\n",
    "        factor_exposures: True factor exposures (betas)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate risk factor returns (e.g., market, size, value, momentum, volatility)\n",
    "    factor_returns = np.random.normal(0, 1, (num_samples, num_risk_factors))\n",
    "    \n",
    "    # Add some autocorrelation to factors (typical in financial time series)\n",
    "    for i in range(1, num_samples):\n",
    "        factor_returns[i] = 0.2 * factor_returns[i-1] + 0.8 * factor_returns[i]\n",
    "    \n",
    "    # Introduce correlations between factors\n",
    "    correlation_matrix = np.eye(num_risk_factors)\n",
    "    # Add some off-diagonal correlations\n",
    "    for i in range(num_risk_factors-1):\n",
    "        correlation_matrix[i, i+1] = 0.3\n",
    "        correlation_matrix[i+1, i] = 0.3\n",
    "    \n",
    "    # Apply Cholesky decomposition for correlated factors\n",
    "    cholesky = np.linalg.cholesky(correlation_matrix)\n",
    "    factor_returns = np.dot(factor_returns, cholesky)\n",
    "    \n",
    "    # Generate factor exposures (betas) for each asset\n",
    "    factor_exposures = np.random.normal(0, 1, (num_assets, num_risk_factors))\n",
    "    \n",
    "    # Make some factors more influential\n",
    "    factor_exposures[:, 0] *= 1.5  # Market factor typically has larger influence\n",
    "    \n",
    "    # Add sector-like clustering\n",
    "    num_sectors = 5\n",
    "    sector_size = num_assets // num_sectors\n",
    "    for s in range(num_sectors):\n",
    "        start_idx = s * sector_size\n",
    "        end_idx = start_idx + sector_size\n",
    "        # Assets in the same sector have similar exposures to certain factors\n",
    "        sector_factor = np.random.randint(1, num_risk_factors)\n",
    "        sector_exposure = np.random.normal(0, 1)\n",
    "        factor_exposures[start_idx:end_idx, sector_factor] = sector_exposure + np.random.normal(0, 0.3, end_idx-start_idx)\n",
    "    \n",
    "    # Generate asset returns based on factor model plus idiosyncratic returns\n",
    "    # R_i = sum_j(beta_ij * F_j) + epsilon_i\n",
    "    asset_returns = np.zeros((num_samples, num_assets))\n",
    "    \n",
    "    # Linear factor model component\n",
    "    for i in range(num_assets):\n",
    "        for j in range(num_risk_factors):\n",
    "            asset_returns[:, i] += factor_exposures[i, j] * factor_returns[:, j]\n",
    "    \n",
    "    # Add non-linear factor effects (to make the problem more challenging and realistic)\n",
    "    for i in range(num_assets):\n",
    "        for j in range(num_risk_factors):\n",
    "            # Add some quadratic effects\n",
    "            if j % 2 == 0:  # For even-indexed factors\n",
    "                asset_returns[:, i] += 0.1 * factor_exposures[i, j] * factor_returns[:, j]**2\n",
    "            # Add some threshold effects\n",
    "            else:  # For odd-indexed factors\n",
    "                threshold_effect = 0.1 * factor_exposures[i, j] * np.maximum(factor_returns[:, j] - 1.0, 0)\n",
    "                asset_returns[:, i] += threshold_effect\n",
    "    \n",
    "    # Add idiosyncratic (asset-specific) returns\n",
    "    idiosyncratic_vol = np.random.uniform(0.5, 1.5, num_assets)\n",
    "    idiosyncratic_returns = np.random.normal(0, 1, (num_samples, num_assets))\n",
    "    for i in range(num_assets):\n",
    "        asset_returns[:, i] += idiosyncratic_vol[i] * idiosyncratic_returns[:, i]\n",
    "    \n",
    "    # Normalize returns to a reasonable scale\n",
    "    asset_returns = asset_returns * 0.01  # 1% daily standard deviation\n",
    "    factor_returns = factor_returns * 0.01\n",
    "    \n",
    "    # Convert to JAX arrays\n",
    "    factor_returns_jax = jnp.array(factor_returns)\n",
    "    asset_returns_jax = jnp.array(asset_returns)\n",
    "    factor_exposures_jax = jnp.array(factor_exposures)\n",
    "    \n",
    "    return factor_returns_jax, asset_returns_jax, factor_exposures_jax\n",
    "\n",
    "# Training functions\n",
    "@jit\n",
    "def loss_fn(params, X, Y):\n",
    "    \"\"\"Mean squared error loss function for risk factor prediction.\"\"\"\n",
    "    model = RiskFactorKAN(X.shape[1], Y.shape[1])\n",
    "    model.update_params(params)\n",
    "    pred = model(X)\n",
    "    return jnp.mean((pred - Y) ** 2)\n",
    "\n",
    "@jit\n",
    "def train_step(params, X, Y, opt_state):\n",
    "    \"\"\"Single optimization step.\"\"\"\n",
    "    loss_value, grads = jax.value_and_grad(loss_fn)(params, X, Y)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss_value\n",
    "\n",
    "def train_model(X, Y, params, num_epochs=100, batch_size=64):\n",
    "    \"\"\"Train the model for a specified number of epochs.\"\"\"\n",
    "    num_samples = X.shape[0]\n",
    "    num_batches = num_samples // batch_size\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    # Initialize optimizer state\n",
    "    opt_state = optimizer.init(params)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle data\n",
    "        perm = jax.random.permutation(jax.random.PRNGKey(epoch), num_samples)\n",
    "        X_shuffled = X[perm]\n",
    "        Y_shuffled = Y[perm]\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch in range(num_batches):\n",
    "            start_idx = batch * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            \n",
    "            X_batch = X_shuffled[start_idx:end_idx]\n",
    "            Y_batch = Y_shuffled[start_idx:end_idx]\n",
    "            \n",
    "            params, opt_state, batch_loss = train_step(params, X_batch, Y_batch, opt_state)\n",
    "            epoch_loss += batch_loss\n",
    "        \n",
    "        epoch_loss /= num_batches\n",
    "        losses.append(epoch_loss)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {epoch_loss:.6f}\")\n",
    "    \n",
    "    return params, losses\n",
    "\n",
    "# Risk attribution and decomposition functions\n",
    "def compute_risk_attribution(model, params, factor_returns, asset_returns):\n",
    "    \"\"\"\n",
    "    Compute risk attribution using the trained KAN model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RiskFactorKAN model\n",
    "        params: Model parameters\n",
    "        factor_returns: Risk factor returns\n",
    "        asset_returns: Asset returns\n",
    "        \n",
    "    Returns:\n",
    "        risk_attribution: Attribution of risk to each factor for each asset\n",
    "    \"\"\"\n",
    "    model.update_params(params)\n",
    "    \n",
    "    # Number of assets and factors\n",
    "    num_assets = asset_returns.shape[1]\n",
    "    num_factors = factor_returns.shape[1]\n",
    "    \n",
    "    # Create a function that maps factors to asset returns for a single asset\n",
    "    def asset_return_fn(factors, asset_idx):\n",
    "        \"\"\"Function that maps factor returns to a single asset's return.\"\"\"\n",
    "        # Expand factors to batch size 1\n",
    "        factors_batch = factors.reshape(1, -1)\n",
    "        # Get all asset predictions and select the asset_idx\n",
    "        return model(factors_batch)[0, asset_idx]\n",
    "    \n",
    "    # Compute Jacobian for each asset with respect to factors\n",
    "    jacobians = []\n",
    "    for asset_idx in range(num_assets):\n",
    "        # Create a function specific to this asset\n",
    "        asset_fn = lambda factors: asset_return_fn(factors, asset_idx)\n",
    "        # Compute Jacobian for all samples\n",
    "        asset_jacobian = jax.vmap(jax.grad(asset_fn))(factor_returns)\n",
    "        jacobians.append(asset_jacobian)\n",
    "    \n",
    "    # Stack jacobians: shape (num_assets, num_samples, num_factors)\n",
    "    jacobians = jnp.stack(jacobians)\n",
    "    \n",
    "    # Compute average sensitivity over all time periods\n",
    "    avg_sensitivity = jnp.mean(jacobians, axis=1)  # Shape: (num_assets, num_factors)\n",
    "    \n",
    "    # Compute factor contributions to asset returns\n",
    "    # For each asset and time period, multiply factor returns by sensitivities\n",
    "    factor_contributions = jnp.zeros((asset_returns.shape[0], num_assets, num_factors))\n",
    "    \n",
    "    for t in range(asset_returns.shape[0]):\n",
    "        for a in range(num_assets):\n",
    "            factor_contributions = factor_contributions.at[t, a].set(\n",
    "                jacobians[a, t] * factor_returns[t]\n",
    "            )\n",
    "    \n",
    "    # Compute variance of factor contributions for risk attribution\n",
    "    factor_contrib_var = jnp.var(factor_contributions, axis=0)  # Shape: (num_assets, num_factors)\n",
    "    \n",
    "    # Compute total variance for each asset\n",
    "    total_var = jnp.var(asset_returns, axis=0)  # Shape: (num_assets,)\n",
    "    \n",
    "    # Compute percentage risk attribution\n",
    "    risk_attribution = factor_contrib_var / total_var.reshape(-1, 1)\n",
    "    \n",
    "    return risk_attribution, avg_sensitivity, factor_contributions\n",
    "\n",
    "# Visualization and analysis functions\n",
    "def visualize_risk_decomposition(risk_attribution, true_exposures, factor_names=None, asset_names=None):\n",
    "    \"\"\"\n",
    "    Visualize risk decomposition and compare with true factor exposures.\n",
    "    \n",
    "    Args:\n",
    "        risk_attribution: Computed risk attribution from KAN model\n",
    "        true_exposures: True factor exposures used to generate data\n",
    "        factor_names: Names of risk factors\n",
    "        asset_names: Names of assets\n",
    "    \"\"\"\n",
    "    # Convert to numpy for plotting\n",
    "    risk_attribution_np = np.array(risk_attribution)\n",
    "    true_exposures_np = np.array(true_exposures)\n",
    "    \n",
    "    # Square true exposures to compare with variance-based attribution\n",
    "    true_exposures_squared = true_exposures_np**2\n",
    "    # Normalize to sum to 1 for percentage comparison\n",
    "    true_exposures_norm = true_exposures_squared / true_exposures_squared.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Provide default names if not provided\n",
    "    if factor_names is None:\n",
    "        factor_names = [f\"Factor {i+1}\" for i in range(risk_attribution_np.shape[1])]\n",
    "    \n",
    "    if asset_names is None:\n",
    "        asset_names = [f\"Asset {i+1}\" for i in range(risk_attribution_np.shape[0])]\n",
    "    \n",
    "    # Number of assets and factors to plot\n",
    "    num_assets_to_plot = min(6, risk_attribution_np.shape[0])\n",
    "    num_factors = risk_attribution_np.shape[1]\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(num_assets_to_plot, 2, figsize=(15, 3 * num_assets_to_plot))\n",
    "    \n",
    "    # Colors for factors\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, num_factors))\n",
    "    \n",
    "    for i in range(num_assets_to_plot):\n",
    "        # Plot KAN-derived risk attribution\n",
    "        axs[i, 0].bar(range(num_factors), risk_attribution_np[i], color=colors)\n",
    "        axs[i, 0].set_title(f\"{asset_names[i]}: KAN Risk Attribution\")\n",
    "        axs[i, 0].set_ylabel(\"Risk Contribution (%)\")\n",
    "        axs[i, 0].set_xticks(range(num_factors))\n",
    "        axs[i, 0].set_xticklabels(factor_names)\n",
    "        axs[i, 0].set_ylim(0, max(1.0, np.max(risk_attribution_np[i]) * 1.1))\n",
    "        \n",
    "        # Plot true factor exposures (squared and normalized)\n",
    "        axs[i, 1].bar(range(num_factors), true_exposures_norm[i], color=colors)\n",
    "        axs[i, 1].set_title(f\"{asset_names[i]}: True Risk Attribution\")\n",
    "        axs[i, 1].set_ylabel(\"Risk Contribution (%)\")\n",
    "        axs[i, 1].set_xticks(range(num_factors))\n",
    "        axs[i, 1].set_xticklabels(factor_names)\n",
    "        axs[i, 1].set_ylim(0, max(1.0, np.max(true_exposures_norm[i]) * 1.1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def analyze_factor_activations(model, factor_returns):\n",
    "    \"\"\"\n",
    "    Analyze the learned activation functions for risk factors.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RiskFactorKAN model\n",
    "        factor_returns: Risk factor returns\n",
    "    \"\"\"\n",
    "    # Get the grid points and activations from the first layer\n",
    "    grid_points = model.layers[0].grid_points\n",
    "    activations = model.layers[0].activations\n",
    "    \n",
    "    # Number of factors and units to visualize\n",
    "    num_factors = factor_returns.shape[1]\n",
    "    num_units = min(4, activations.shape[0])\n",
    "    \n",
    "    # Create a figure\n",
    "    fig, axs = plt.subplots(num_units, 1, figsize=(10, 2.5 * num_units))\n",
    "    \n",
    "    # Plot learned activations\n",
    "    for i in range(num_units):\n",
    "        axs[i].plot(grid_points, activations[i])\n",
    "        axs[i].set_title(f\"Learned Activation for Hidden Unit {i+1}\")\n",
    "        axs[i].set_xlabel(\"Input\")\n",
    "        axs[i].set_ylabel(\"Activation\")\n",
    "        axs[i].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def factor_correlation_analysis(model, params, factor_returns, asset_returns):\n",
    "    \"\"\"\n",
    "    Analyze how KAN-derived factors correlate with true factors.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RiskFactorKAN model\n",
    "        params: Model parameters\n",
    "        factor_returns: True factor returns\n",
    "        asset_returns: Asset returns\n",
    "    \"\"\"\n",
    "    # Update model with parameters\n",
    "    model.update_params(params)\n",
    "    \n",
    "    # Define a function to extract intermediate activations\n",
    "    # We'll use the first hidden layer as \"KAN-derived factors\"\n",
    "    def get_first_layer_activations(inputs):\n",
    "        return model.layers[0](inputs)\n",
    "    \n",
    "    # Get KAN-derived factors\n",
    "    kan_factors = get_first_layer_activations(factor_returns)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    kan_factors_np = np.array(kan_factors)\n",
    "    factor_returns_np = np.array(factor_returns)\n",
    "    \n",
    "    # Calculate correlation between KAN factors and true factors\n",
    "    correlations = np.zeros((kan_factors_np.shape[1], factor_returns_np.shape[1]))\n",
    "    \n",
    "    for i in range(kan_factors_np.shape[1]):\n",
    "        for j in range(factor_returns_np.shape[1]):\n",
    "            correlations[i, j] = np.corrcoef(kan_factors_np[:, i], factor_returns_np[:, j])[0, 1]\n",
    "    \n",
    "    # Visualize correlations\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    im = ax.imshow(correlations, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    cbar.ax.set_ylabel(\"Correlation\", rotation=-90, va=\"bottom\")\n",
    "    \n",
    "    # Set labels\n",
    "    ax.set_xlabel(\"True Factors\")\n",
    "    ax.set_ylabel(\"KAN-derived Factors\")\n",
    "    \n",
    "    # Add tick labels\n",
    "    ax.set_xticks(np.arange(factor_returns_np.shape[1]))\n",
    "    ax.set_yticks(np.arange(kan_factors_np.shape[1]))\n",
    "    ax.set_xticklabels([f\"Factor {i+1}\" for i in range(factor_returns_np.shape[1])])\n",
    "    ax.set_yticklabels([f\"KAN Factor {i+1}\" for i in range(kan_factors_np.shape[1])])\n",
    "    \n",
    "    plt.title(\"Correlation between KAN-derived Factors and True Factors\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, correlations\n",
    "\n",
    "def stress_test_analysis(model, params, factor_returns, asset_returns, stress_magnitude=3.0):\n",
    "    \"\"\"\n",
    "    Perform stress test analysis on the portfolio using the KAN model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained RiskFactorKAN model\n",
    "        params: Model parameters\n",
    "        factor_returns: Risk factor returns\n",
    "        asset_returns: Asset returns\n",
    "        stress_magnitude: Magnitude of stress scenarios in standard deviations\n",
    "    \"\"\"\n",
    "    # Update model with parameters\n",
    "    model.update_params(params)\n",
    "    \n",
    "    # Number of factors\n",
    "    num_factors = factor_returns.shape[1]\n",
    "    \n",
    "    # Calculate factor means and standard deviations\n",
    "    factor_means = jnp.mean(factor_returns, axis=0)\n",
    "    factor_stds = jnp.std(factor_returns, axis=0)\n",
    "    \n",
    "    # Create stress scenarios: one for each factor\n",
    "    # Each scenario stresses one factor by stress_magnitude standard deviations\n",
    "    stress_scenarios = []\n",
    "    for i in range(num_factors):\n",
    "        scenario = factor_means.copy()\n",
    "        scenario = scenario.at[i].set(factor_means[i] + stress_magnitude * factor_stds[i])\n",
    "        stress_scenarios.append(scenario)\n",
    "    \n",
    "    # Convert to batch for model prediction\n",
    "    stress_scenarios = jnp.stack(stress_scenarios)\n",
    "    \n",
    "    # Predict asset returns under stress scenarios\n",
    "    stress_returns = model(stress_scenarios)\n",
    "    \n",
    "    # Calculate portfolio returns (assuming equal weighting for simplicity)\n",
    "    portfolio_weights = jnp.ones(asset_returns.shape[1]) / asset_returns.shape[1]\n",
    "    portfolio_stress_returns = jnp.dot(stress_returns, portfolio_weights)\n",
    "    \n",
    "    # Calculate normal portfolio return\n",
    "    normal_return = jnp.dot(model(factor_means.reshape(1, -1))[0], portfolio_weights)\n",
    "    \n",
    "    # Calculate percentage changes\n",
    "    percentage_changes = (portfolio_stress_returns - normal_return) / jnp.abs(normal_return) * 100\n",
    "    \n",
    "    # Create a figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Plot stress test results\n",
    "    bars = ax.bar(range(num_factors), percentage_changes)\n",
    "    \n",
    "    # Color bars based on positive/negative changes\n",
    "    for i, bar in enumerate(bars):\n",
    "        if percentage_changes[i] < 0:\n",
    "            bar.set_color('red')\n",
    "        else:\n",
    "            bar.set_color('green')\n",
    "    \n",
    "    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax.set_xlabel('Stressed Factor')\n",
    "    ax.set_ylabel('Portfolio Return Change (%)')\n",
    "    ax.set_title(f'Portfolio Stress Test (Factor Shocks: {stress_magnitude} std)')\n",
    "    ax.set_xticks(range(num_factors))\n",
    "    ax.set_xticklabels([f\"Factor {i+1}\" for i in range(num_factors)])\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    return fig, percentage_changes\n",
    "\n",
    "# Main function to run everything\n",
    "def main():\n",
    "    # Generate synthetic data\n",
    "    print(\"Generating synthetic risk factor data...\")\n",
    "    factor_returns, asset_returns, true_exposures = generate_risk_factor_data(\n",
    "        num_samples=2000, num_risk_factors=5, num_assets=20)\n",
    "    \n",
    "    # Split into train/test sets\n",
    "    train_size = int(0.8 * factor_returns.shape[0])\n",
    "    factor_returns_train = factor_returns[:train_size]\n",
    "    factor_returns_test = factor_returns[train_size:]\n",
    "    asset_returns_train = asset_returns[:train_size]\n",
    "    asset_returns_test = asset_returns[train_size:]\n",
    "    \n",
    "    # Initialize model\n",
    "    print(\"Initializing KAN model for risk factor decomposition...\")\n",
    "    input_dim = factor_returns.shape[1]  # Number of risk factors\n",
    "    output_dim = asset_returns.shape[1]  # Number of assets\n",
    "    \n",
    "    model = RiskFactorKAN(input_dim, output_dim, hidden_dims=[32, 16])\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    global optimizer  # Make accessible to JIT-compiled functions\n",
    "    learning_rate = 0.001\n",
    "    optimizer = optax.adam(learning_rate)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    trained_params, losses = train_model(factor_returns_train, asset_returns_train, model.params, num_epochs=100)\n",
    "    \n",
    "    # Evaluate model on test set\n",
    "    model.update_params(trained_params)\n",
    "    test_predictions = model(factor_returns_test)\n",
    "    test_mse = jnp.mean((test_predictions - asset_returns_test) ** 2)\n",
    "    print(f\"Test MSE: {test_mse:.6f}\")\n",
    "    \n",
    "    # Compute risk attribution\n",
    "    print(\"Computing risk attribution...\")\n",
    "    risk_attribution, sensitivity, factor_contributions = compute_risk_attribution(\n",
    "        model, trained_params, factor_returns, asset_returns)\n",
    "    \n",
    "    # Define factor names for visualization\n",
    "    factor_names = [\"Market\", \"Size\", \"Value\", \"Momentum\", \"Volatility\"][:factor_returns.shape[1]]\n",
    "    \n",
    "    # Visualize risk decomposition\n",
    "    print(\"Visualizing risk decomposition...\")\n",
    "    fig_risk = visualize_risk_decomposition(risk_attribution, true_exposures, factor_names)\n",
    "    \n",
    "    # Analyze factor activations\n",
    "    print(\"Analyzing factor activations...\")\n",
    "    model.update_params(trained_params)\n",
    "    fig_activations = analyze_factor_activations(model, factor_returns)\n",
    "    \n",
    "    # Factor correlation analysis\n",
    "    print(\"Analyzing factor correlations...\")\n",
    "    fig_corr, correlations = factor_correlation_analysis(model, trained_params, factor_returns, asset_returns)\n",
    "    \n",
    "    # Stress test analysis\n",
    "    print(\"Performing stress test analysis...\")\n",
    "    fig_stress, stress_results = stress_test_analysis(model, trained_params, factor_returns, asset_returns)\n",
    "    \n",
    "    # Return results\n",
    "    return model, trained_params, losses, risk_attribution, fig_risk, fig_activations, fig_corr, fig_stress\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
