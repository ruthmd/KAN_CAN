{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0c55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optax yfinance lxml plotly hmmlearn \"jax[cuda12]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a30396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, vmap, jit\n",
    "import numpy as np\n",
    "import optax\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple, Callable, Any\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "# KAN Layer implementation for portfolio optimization\n",
    "class KANLayer:\n",
    "    def __init__(self, input_dim: int, output_dim: int, num_basis: int = 30, \n",
    "                 domain=(-3.0, 3.0), key=None):\n",
    "        \"\"\"Initialize a KAN layer with learnable activation functions.\n",
    "        \n",
    "        Args:\n",
    "            input_dim: Input dimension\n",
    "            output_dim: Output dimension\n",
    "            num_basis: Number of basis functions for learned activation\n",
    "            domain: Domain over which the activation functions are defined\n",
    "            key: JAX random key\n",
    "        \"\"\"\n",
    "        if key is None:\n",
    "            key = jax.random.PRNGKey(0)\n",
    "        \n",
    "        key1, key2, key3 = jax.random.split(key, 3)\n",
    "        \n",
    "        # Initialize weights for linear transformation\n",
    "        self.weights = jax.random.normal(key1, (input_dim, output_dim)) * 0.1\n",
    "        \n",
    "        # Initialize biases\n",
    "        self.biases = jax.random.normal(key2, (output_dim,)) * 0.01\n",
    "        \n",
    "        # Grid points for activation function representation\n",
    "        self.grid_points = jnp.linspace(domain[0], domain[1], num_basis)\n",
    "        \n",
    "        # Initialize activation function values with different shapes\n",
    "        activations_list = []\n",
    "        for i in range(output_dim):\n",
    "            subkey = jax.random.fold_in(key3, i)\n",
    "            init_type = jax.random.randint(subkey, (), 0, 4)\n",
    "            \n",
    "            if init_type == 0:  # Linear-like\n",
    "                act = self.grid_points\n",
    "            elif init_type == 1:  # ReLU-like\n",
    "                act = jnp.maximum(0, self.grid_points)\n",
    "            elif init_type == 2:  # Sigmoid-like\n",
    "                act = 1.0 / (1.0 + jnp.exp(-self.grid_points))\n",
    "            else:  # Tanh-like\n",
    "                act = jnp.tanh(self.grid_points)\n",
    "            \n",
    "            # Add noise to break symmetry\n",
    "            act = act + jax.random.normal(subkey, (num_basis,)) * 0.05\n",
    "            activations_list.append(act)\n",
    "        \n",
    "        # Stack into a matrix: (output_dim, num_basis)\n",
    "        self.activations = jnp.stack(activations_list)\n",
    "        \n",
    "        # Store domain for clipping\n",
    "        self.domain = domain\n",
    "    \n",
    "    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        \"\"\"Forward pass through the KAN layer.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, input_dim)\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor of shape (batch_size, output_dim)\n",
    "        \"\"\"\n",
    "        # Linear transformation\n",
    "        z = jnp.dot(x, self.weights) + self.biases  # Shape: (batch_size, output_dim)\n",
    "        \n",
    "        # Apply learned activation functions by interpolation\n",
    "        z_clipped = jnp.clip(z, self.domain[0], self.domain[1])\n",
    "        \n",
    "        def apply_activation(z_i, i):\n",
    "            \"\"\"Apply the i-th activation function to z_i using linear interpolation.\"\"\"\n",
    "            idx = jnp.searchsorted(self.grid_points, z_i) - 1\n",
    "            idx = jnp.clip(idx, 0, len(self.grid_points) - 2)\n",
    "            \n",
    "            x0 = self.grid_points[idx]\n",
    "            x1 = self.grid_points[idx + 1]\n",
    "            y0 = self.activations[i, idx]\n",
    "            y1 = self.activations[i, idx + 1]\n",
    "            \n",
    "            t = (z_i - x0) / (x1 - x0)\n",
    "            return y0 + t * (y1 - y0)\n",
    "        \n",
    "        # Apply activation function for each element in the batch and each output dimension\n",
    "        output = jnp.zeros_like(z)\n",
    "        for i in range(z.shape[1]):  # For each output dimension\n",
    "            output = output.at[:, i].set(vmap(lambda z_i: apply_activation(z_i, i))(z_clipped[:, i]))\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "\n",
    "# Portfolio Optimization KAN model\n",
    "class PortfolioKAN:\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dims: List[int] = [64, 32], \n",
    "                 num_basis: int = 30, domain=(-3.0, 3.0), key=None):\n",
    "        \"\"\"Initialize a KAN model for portfolio optimization.\n",
    "        \n",
    "        Args:\n",
    "            input_dim: Input dimension (market factors, asset features)\n",
    "            output_dim: Output dimension (portfolio weights)\n",
    "            hidden_dims: List of hidden dimensions\n",
    "            num_basis: Number of basis functions for learned activations\n",
    "            domain: Domain for activation functions\n",
    "            key: JAX random key\n",
    "        \"\"\"\n",
    "        if key is None:\n",
    "            key = jax.random.PRNGKey(0)\n",
    "        \n",
    "        keys = jax.random.split(key, len(hidden_dims) + 1)\n",
    "        \n",
    "        # Initialize layers\n",
    "        self.layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layer = KANLayer(prev_dim, hidden_dim, num_basis, domain, keys[i])\n",
    "            self.layers.append(layer)\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Final layer for portfolio weights\n",
    "        self.output_layer = KANLayer(prev_dim, output_dim, num_basis, domain, keys[-1])\n",
    "    \n",
    "    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        \"\"\"Forward pass through the KAN model.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, input_dim)\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor of shape (batch_size, output_dim) representing portfolio weights\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Apply output layer\n",
    "        raw_weights = self.output_layer(x)\n",
    "        \n",
    "        # Apply softmax to ensure weights sum to 1 (fully invested)\n",
    "        portfolio_weights = jax.nn.softmax(raw_weights, axis=-1)\n",
    "        \n",
    "        return portfolio_weights\n",
    "    \n",
    "    @property\n",
    "    def params(self):\n",
    "        \"\"\"Get model parameters as a flat dictionary.\"\"\"\n",
    "        params = {}\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            params[f'layer_{i}_weights'] = layer.weights\n",
    "            params[f'layer_{i}_biases'] = layer.biases\n",
    "            params[f'layer_{i}_activations'] = layer.activations\n",
    "        \n",
    "        params['output_layer_weights'] = self.output_layer.weights\n",
    "        params['output_layer_biases'] = self.output_layer.biases\n",
    "        params['output_layer_activations'] = self.output_layer.activations\n",
    "        \n",
    "        return params\n",
    "    \n",
    "    def update_params(self, params):\n",
    "        \"\"\"Update model parameters from a flat dictionary.\"\"\"\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            layer.weights = params[f'layer_{i}_weights']\n",
    "            layer.biases = params[f'layer_{i}_biases']\n",
    "            layer.activations = params[f'layer_{i}_activations']\n",
    "        \n",
    "        self.output_layer.weights = params['output_layer_weights']\n",
    "        self.output_layer.biases = params['output_layer_biases']\n",
    "        self.output_layer.activations = params['output_layer_activations']\n",
    "\n",
    "# Data generation and utilities for portfolio optimization\n",
    "def generate_market_data(num_periods=1000, num_assets=10, num_factors=3, seed=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic market data with a factor structure.\n",
    "    \n",
    "    Args:\n",
    "        num_periods: Number of time periods\n",
    "        num_assets: Number of assets\n",
    "        num_factors: Number of risk factors\n",
    "        seed: Random seed\n",
    "        \n",
    "    Returns:\n",
    "        returns: Asset returns\n",
    "        factors: Factor returns\n",
    "        factor_exposures: Asset exposures to factors\n",
    "        feature_data: Asset features\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate factor returns\n",
    "    factor_volatility = np.random.uniform(0.01, 0.05, num_factors)\n",
    "    factor_returns = np.random.normal(0, factor_volatility, (num_periods, num_factors))\n",
    "    \n",
    "    # Generate factor exposures for each asset\n",
    "    factor_exposures = np.random.normal(0, 1, (num_assets, num_factors))\n",
    "    \n",
    "    # Idiosyncratic volatility for each asset\n",
    "    idiosyncratic_vol = np.random.uniform(0.01, 0.05, num_assets)\n",
    "    \n",
    "    # Generate asset returns based on factor model plus idiosyncratic returns\n",
    "    asset_returns = np.zeros((num_periods, num_assets))\n",
    "    \n",
    "    for i in range(num_periods):\n",
    "        # Systematic returns from factors\n",
    "        systematic_returns = np.dot(factor_returns[i], factor_exposures.T)\n",
    "        \n",
    "        # Idiosyncratic returns\n",
    "        idiosyncratic_returns = np.random.normal(0, idiosyncratic_vol)\n",
    "        \n",
    "        # Total returns\n",
    "        asset_returns[i] = systematic_returns + idiosyncratic_returns\n",
    "    \n",
    "    # Generate asset features (market cap, value, momentum, etc.)\n",
    "    feature_data = np.zeros((num_periods, num_assets, 5))\n",
    "    \n",
    "    # Market cap (size) - relatively stable over time\n",
    "    size = np.random.lognormal(10, 2, num_assets)\n",
    "    for i in range(num_periods):\n",
    "        # Market cap grows/shrinks slowly\n",
    "        size = size * np.exp(np.random.normal(0, 0.01, num_assets))\n",
    "        feature_data[i, :, 0] = size\n",
    "    \n",
    "    # Value ratio (e.g., book-to-market) - changes slowly\n",
    "    value_ratio = np.random.normal(1, 0.5, num_assets)\n",
    "    for i in range(num_periods):\n",
    "        # Value ratio changes slowly\n",
    "        if i > 0:\n",
    "            value_ratio = 0.98 * value_ratio + 0.02 * np.random.normal(1, 0.5, num_assets)\n",
    "        feature_data[i, :, 1] = value_ratio\n",
    "    \n",
    "    # Momentum (trailing 12-period returns)\n",
    "    for i in range(num_periods):\n",
    "        if i >= 12:\n",
    "            momentum = np.prod(1 + asset_returns[i-12:i], axis=0) - 1\n",
    "        else:\n",
    "            momentum = np.zeros(num_assets)\n",
    "        feature_data[i, :, 2] = momentum\n",
    "    \n",
    "    # Volatility (trailing 20-period volatility)\n",
    "    for i in range(num_periods):\n",
    "        if i >= 20:\n",
    "            volatility = np.std(asset_returns[i-20:i], axis=0)\n",
    "        else:\n",
    "            volatility = idiosyncratic_vol\n",
    "        feature_data[i, :, 3] = volatility\n",
    "    \n",
    "    # Quality (synthetic quality score that correlates with returns)\n",
    "    quality = np.random.normal(0, 1, num_assets)\n",
    "    for i in range(num_periods):\n",
    "        # Quality is somewhat persistent\n",
    "        if i > 0:\n",
    "            quality = 0.95 * quality + 0.05 * np.random.normal(0, 1, num_assets)\n",
    "        # Higher quality tends to correlate with slightly better returns\n",
    "        feature_data[i, :, 4] = quality\n",
    "    \n",
    "    return asset_returns, factor_returns, factor_exposures, feature_data\n",
    "\n",
    "def prepare_portfolio_data(returns, features, lookback=20, test_split=0.2):\n",
    "    \"\"\"\n",
    "    Prepare data for portfolio optimization.\n",
    "    \n",
    "    Args:\n",
    "        returns: Asset returns (periods x assets)\n",
    "        features: Asset features (periods x assets x features)\n",
    "        lookback: Number of periods to include in each input window\n",
    "        test_split: Fraction of data to use for testing\n",
    "        \n",
    "    Returns:\n",
    "        X_train, y_train, X_test, y_test: Training and testing data\n",
    "    \"\"\"\n",
    "    num_periods, num_assets, num_features = features.shape\n",
    "    \n",
    "    # Create input-output pairs\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for t in range(lookback, num_periods-1):\n",
    "        # Input: historical returns and features\n",
    "        x_t = []\n",
    "        \n",
    "        # 1. Historical returns for each asset\n",
    "        for a in range(num_assets):\n",
    "            x_t.extend(returns[t-lookback:t, a])\n",
    "        \n",
    "        # 2. Current features for each asset\n",
    "        for a in range(num_assets):\n",
    "            x_t.extend(features[t, a])\n",
    "        \n",
    "        X.append(x_t)\n",
    "        \n",
    "        # Output: next period returns (for computing objective function)\n",
    "        y.append(returns[t+1])\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    train_size = int(len(X) * (1 - test_split))\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    # Convert to JAX arrays\n",
    "    X_train = jnp.array(X_train)\n",
    "    y_train = jnp.array(y_train)\n",
    "    X_test = jnp.array(X_test)\n",
    "    y_test = jnp.array(y_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Loss functions for portfolio optimization\n",
    "def sharpe_ratio_loss(portfolio_weights, returns, annualization_factor=252, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    Negative Sharpe ratio loss function.\n",
    "    \n",
    "    Args:\n",
    "        portfolio_weights: Portfolio weights (batch_size, num_assets)\n",
    "        returns: Asset returns (batch_size, num_assets)\n",
    "        annualization_factor: Factor to annualize returns\n",
    "        risk_free_rate: Risk-free rate\n",
    "        \n",
    "    Returns:\n",
    "        negative_sharpe: Negative Sharpe ratio (to minimize)\n",
    "    \"\"\"\n",
    "    # Portfolio returns\n",
    "    portfolio_returns = jnp.sum(portfolio_weights * returns, axis=1)\n",
    "    \n",
    "    # Mean return\n",
    "    mean_return = jnp.mean(portfolio_returns)\n",
    "    \n",
    "    # Portfolio volatility\n",
    "    portfolio_vol = jnp.std(portfolio_returns)\n",
    "    \n",
    "    # Annualize\n",
    "    mean_return_annual = mean_return * annualization_factor\n",
    "    portfolio_vol_annual = portfolio_vol * jnp.sqrt(annualization_factor)\n",
    "    \n",
    "    # Compute Sharpe ratio\n",
    "    sharpe_ratio = (mean_return_annual - risk_free_rate) / portfolio_vol_annual\n",
    "    \n",
    "    # Return negative sharpe ratio (for minimization)\n",
    "    return -sharpe_ratio\n",
    "\n",
    "def mean_variance_loss(portfolio_weights, returns, risk_aversion=1.0):\n",
    "    \"\"\"\n",
    "    Mean-variance loss function.\n",
    "    \n",
    "    Args:\n",
    "        portfolio_weights: Portfolio weights (batch_size, num_assets)\n",
    "        returns: Asset returns (batch_size, num_assets)\n",
    "        risk_aversion: Risk aversion parameter\n",
    "        \n",
    "    Returns:\n",
    "        loss: Mean-variance loss\n",
    "    \"\"\"\n",
    "    # Portfolio returns\n",
    "    portfolio_returns = jnp.sum(portfolio_weights * returns, axis=1)\n",
    "    \n",
    "    # Mean return\n",
    "    mean_return = jnp.mean(portfolio_returns)\n",
    "    \n",
    "    # Portfolio variance\n",
    "    portfolio_var = jnp.var(portfolio_returns)\n",
    "    \n",
    "    # Mean-variance objective\n",
    "    loss = -mean_return + risk_aversion * portfolio_var\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def cvar_loss(portfolio_weights, returns, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Conditional Value at Risk (CVaR) loss function.\n",
    "    \n",
    "    Args:\n",
    "        portfolio_weights: Portfolio weights (batch_size, num_assets)\n",
    "        returns: Asset returns (batch_size, num_assets)\n",
    "        alpha: Confidence level (e.g., 0.05 for 95% CVaR)\n",
    "        \n",
    "    Returns:\n",
    "        cvar: Conditional Value at Risk\n",
    "    \"\"\"\n",
    "    # Portfolio returns\n",
    "    portfolio_returns = jnp.sum(portfolio_weights * returns, axis=1)\n",
    "    \n",
    "    # Sort returns (ascending)\n",
    "    sorted_returns = jnp.sort(portfolio_returns)\n",
    "    \n",
    "    # Find cutoff index\n",
    "    n = len(sorted_returns)\n",
    "    cutoff_index = int(jnp.ceil(n * alpha))\n",
    "    \n",
    "    # Calculate CVaR\n",
    "    cvar = -jnp.mean(sorted_returns[:cutoff_index])\n",
    "    \n",
    "    return cvar\n",
    "\n",
    "# Combined loss with regularization\n",
    "def portfolio_loss_fn(params, model_apply_fn, X, returns, grid_points, loss_type='sharpe', \n",
    "                     lambda_l2=0.001, lambda_smooth=0.001, lambda_turnover=0.001,\n",
    "                     previous_weights=None):\n",
    "    \"\"\"\n",
    "    Combined loss function for portfolio optimization.\n",
    "    \n",
    "    Args:\n",
    "        params: Model parameters\n",
    "        model_apply_fn: Function to apply the model with given parameters\n",
    "        X: Input features\n",
    "        returns: Asset returns\n",
    "        grid_points: Grid points for activation functions\n",
    "        loss_type: Type of portfolio loss function ('sharpe', 'mean_variance', 'cvar')\n",
    "        lambda_l2: L2 regularization strength\n",
    "        lambda_smooth: Activation smoothness regularization strength\n",
    "        lambda_turnover: Portfolio turnover regularization strength\n",
    "        previous_weights: Previous portfolio weights for turnover calculation\n",
    "    \"\"\"\n",
    "    portfolio_weights = model_apply_fn(params, X, grid_points)\n",
    "    \n",
    "    # Calculate portfolio loss based on type\n",
    "    if loss_type == 'sharpe':\n",
    "        portfolio_loss = sharpe_ratio_loss(portfolio_weights, returns)\n",
    "    elif loss_type == 'mean_variance':\n",
    "        portfolio_loss = mean_variance_loss(portfolio_weights, returns)\n",
    "    elif loss_type == 'cvar':\n",
    "        portfolio_loss = cvar_loss(portfolio_weights, returns)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown loss type: {loss_type}\")\n",
    "    \n",
    "    # L2 regularization for weights\n",
    "    l2_reg = 0.0\n",
    "    for layer_idx in range(len(params) // 3 - 1):  # All but output layer\n",
    "        l2_reg += jnp.sum(params[f'layer_{layer_idx}_weights'] ** 2)\n",
    "    l2_reg += jnp.sum(params['output_layer_weights'] ** 2)\n",
    "    \n",
    "    # Smoothness regularization for activations\n",
    "    smooth_reg = 0.0\n",
    "    for layer_idx in range(len(params) // 3 - 1):  # All but output layer\n",
    "        activations = params[f'layer_{layer_idx}_activations']\n",
    "        # Calculate second derivatives (approximation)\n",
    "        second_deriv = activations[:, 2:] - 2 * activations[:, 1:-1] + activations[:, :-2]\n",
    "        smooth_reg += jnp.mean(second_deriv ** 2)\n",
    "    \n",
    "    # Add regularization for output layer\n",
    "    output_activations = params['output_layer_activations']\n",
    "    second_deriv = output_activations[:, 2:] - 2 * output_activations[:, 1:-1] + output_activations[:, :-2]\n",
    "    smooth_reg += jnp.mean(second_deriv ** 2)\n",
    "    \n",
    "    # Turnover regularization (if previous weights provided)\n",
    "    turnover_reg = 0.0\n",
    "    if previous_weights is not None:\n",
    "        # Calculate average turnover across the batch\n",
    "        turnover = jnp.mean(jnp.sum(jnp.abs(portfolio_weights - previous_weights), axis=1))\n",
    "        turnover_reg = turnover\n",
    "    \n",
    "    # Combined loss\n",
    "    total_loss = portfolio_loss + lambda_l2 * l2_reg + lambda_smooth * smooth_reg + lambda_turnover * turnover_reg\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "# Define model forward function separately for JIT\n",
    "def model_forward(params, X, grid_points):\n",
    "    \"\"\"Forward pass without the model object, just using parameters and inputs.\"\"\"\n",
    "    num_layers = (len(params) - 3) // 3  # Subtract output layer params, divide by params per layer\n",
    "    \n",
    "    # Extract parameters for all hidden layers\n",
    "    hidden_params = {}\n",
    "    for i in range(num_layers):\n",
    "        hidden_params[f'layer_{i}_weights'] = params[f'layer_{i}_weights']\n",
    "        hidden_params[f'layer_{i}_biases'] = params[f'layer_{i}_biases']\n",
    "        hidden_params[f'layer_{i}_activations'] = params[f'layer_{i}_activations']\n",
    "    \n",
    "    # Extract output layer parameters\n",
    "    output_weights = params['output_layer_weights']\n",
    "    output_biases = params['output_layer_biases']\n",
    "    output_activations = params['output_layer_activations']\n",
    "    \n",
    "    # Forward pass through hidden layers\n",
    "    z = X\n",
    "    for i in range(num_layers):\n",
    "        # Linear transformation\n",
    "        z = jnp.dot(z, hidden_params[f'layer_{i}_weights']) + hidden_params[f'layer_{i}_biases']\n",
    "        \n",
    "        # Apply learned activation functions\n",
    "        z_clipped = jnp.clip(z, grid_points[0], grid_points[-1])\n",
    "        \n",
    "        # Apply activation function for each element using vectorized operations\n",
    "        z_new = jnp.zeros_like(z)\n",
    "        for j in range(z.shape[1]):\n",
    "            # Find indices for interpolation\n",
    "            idx = jnp.searchsorted(grid_points, z_clipped[:, j]) - 1\n",
    "            idx = jnp.clip(idx, 0, len(grid_points) - 2)\n",
    "            \n",
    "            # Get interpolation points\n",
    "            x0 = grid_points[idx]\n",
    "            x1 = grid_points[idx + 1]\n",
    "            y0 = jnp.take(hidden_params[f'layer_{i}_activations'][j], idx)\n",
    "            y1 = jnp.take(hidden_params[f'layer_{i}_activations'][j], idx + 1)\n",
    "            \n",
    "            # Linear interpolation\n",
    "            t = (z_clipped[:, j] - x0) / (x1 - x0)\n",
    "            z_new = z_new.at[:, j].set(y0 + t * (y1 - y0))\n",
    "        \n",
    "        z = z_new\n",
    "    \n",
    "    # Output layer\n",
    "    z = jnp.dot(z, output_weights) + output_biases\n",
    "    z_clipped = jnp.clip(z, grid_points[0], grid_points[-1])\n",
    "    \n",
    "    # Apply output activation\n",
    "    z_new = jnp.zeros_like(z)\n",
    "    for j in range(z.shape[1]):\n",
    "        # Find indices for interpolation\n",
    "        idx = jnp.searchsorted(grid_points, z_clipped[:, j]) - 1\n",
    "        idx = jnp.clip(idx, 0, len(grid_points) - 2)\n",
    "        \n",
    "        # Get interpolation points\n",
    "        x0 = grid_points[idx]\n",
    "        x1 = grid_points[idx + 1]\n",
    "        y0 = jnp.take(output_activations[j], idx)\n",
    "        y1 = jnp.take(output_activations[j], idx + 1)\n",
    "        \n",
    "        # Linear interpolation\n",
    "        t = (z_clipped[:, j] - x0) / (x1 - x0)\n",
    "        z_new = z_new.at[:, j].set(y0 + t * (y1 - y0))\n",
    "    \n",
    "    # Apply softmax to ensure weights sum to 1\n",
    "    portfolio_weights = jax.nn.softmax(z_new, axis=-1)\n",
    "    \n",
    "    return portfolio_weights\n",
    "\n",
    "def min_var_objective(weights, cov_matrix):\n",
    "    \"\"\"\n",
    "    Objective function for minimum variance portfolio.\n",
    "    \n",
    "    Args:\n",
    "        weights: Portfolio weights\n",
    "        cov_matrix: Covariance matrix of returns\n",
    "        \n",
    "    Returns:\n",
    "        Portfolio variance\n",
    "    \"\"\"\n",
    "    weights = np.array(weights)\n",
    "    portfolio_var = np.dot(weights.T, np.dot(cov_matrix, weights))\n",
    "    return portfolio_var\n",
    "\n",
    "def weight_sum_constraint(weights):\n",
    "    \"\"\"\n",
    "    Constraint function to ensure weights sum to 1.\n",
    "    \n",
    "    Args:\n",
    "        weights: Portfolio weights\n",
    "        \n",
    "    Returns:\n",
    "        Constraint value (0 when sum of weights equals 1)\n",
    "    \"\"\"\n",
    "    return np.sum(weights) - 1.0\n",
    "\n",
    "def neg_sharpe_ratio(weights, returns, cov_matrix, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    Negative Sharpe ratio for optimization.\n",
    "    \n",
    "    Args:\n",
    "        weights: Portfolio weights\n",
    "        returns: Asset returns\n",
    "        cov_matrix: Covariance matrix\n",
    "        risk_free_rate: Risk-free rate\n",
    "        \n",
    "    Returns:\n",
    "        Negative Sharpe ratio\n",
    "    \"\"\"\n",
    "    weights = np.array(weights)\n",
    "    portfolio_return = np.mean(returns.dot(weights))\n",
    "    portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return -(portfolio_return - risk_free_rate) / portfolio_vol\n",
    "\n",
    "def risk_parity_objective(weights, cov_matrix):\n",
    "    \"\"\"\n",
    "    Objective function for risk parity portfolio.\n",
    "    \n",
    "    Args:\n",
    "        weights: Portfolio weights\n",
    "        cov_matrix: Covariance matrix\n",
    "        \n",
    "    Returns:\n",
    "        Sum of squared differences from equal risk contribution\n",
    "    \"\"\"\n",
    "    weights = np.array(weights)\n",
    "    num_assets = len(weights)\n",
    "    portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    \n",
    "    # Calculate risk contribution of each asset\n",
    "    marginal_risk = np.dot(cov_matrix, weights)\n",
    "    risk_contribution = weights * marginal_risk / portfolio_vol\n",
    "    \n",
    "    # Target equal risk contribution\n",
    "    target_risk = portfolio_vol / num_assets\n",
    "    risk_diff = risk_contribution - target_risk\n",
    "    \n",
    "    # Sum of squared differences\n",
    "    return np.sum(risk_diff ** 2)\n",
    "\n",
    "def calculate_portfolio_metrics(returns, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics for a portfolio.\n",
    "    \n",
    "    Args:\n",
    "        returns: Portfolio returns\n",
    "        risk_free_rate: Risk-free rate\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of performance metrics\n",
    "    \"\"\"\n",
    "    annualization_factor = 252  # Assuming daily returns\n",
    "    \n",
    "    # Mean return\n",
    "    mean_return = np.mean(returns)\n",
    "    annual_return = mean_return * annualization_factor\n",
    "    \n",
    "    # Volatility\n",
    "    volatility = np.std(returns)\n",
    "    annual_volatility = volatility * np.sqrt(annualization_factor)\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    sharpe_ratio = (annual_return - risk_free_rate) / annual_volatility\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cumulative_returns = np.cumprod(1 + returns)\n",
    "    peak = np.maximum.accumulate(cumulative_returns)\n",
    "    drawdown = (peak - cumulative_returns) / peak\n",
    "    max_drawdown = np.max(drawdown)\n",
    "    \n",
    "    # Value at Risk (VaR) at 95% confidence\n",
    "    var_95 = -np.percentile(returns, 5)\n",
    "    \n",
    "    # Conditional Value at Risk (CVaR) at 95% confidence\n",
    "    cvar_mask = returns <= -var_95\n",
    "    if np.any(cvar_mask):\n",
    "        cvar_95 = -np.mean(returns[cvar_mask])\n",
    "    else:\n",
    "        cvar_95 = var_95  # Fallback if no returns below VaR\n",
    "    \n",
    "    return {\n",
    "        'annual_return': annual_return,\n",
    "        'annual_volatility': annual_volatility,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'var_95': var_95,\n",
    "        'cvar_95': cvar_95\n",
    "    }\n",
    "\n",
    "def compare_with_traditional_methods(asset_returns, features, test_start_idx, kan_weights, kan_metrics):\n",
    "    \"\"\"\n",
    "    Compare KAN portfolio with traditional portfolio optimization methods.\n",
    "    \n",
    "    Args:\n",
    "        asset_returns: Asset returns\n",
    "        features: Asset features\n",
    "        test_start_idx: Starting index of test data\n",
    "        kan_weights: KAN portfolio weights (from model)\n",
    "        kan_metrics: KAN performance metrics\n",
    "        \n",
    "    Returns:\n",
    "        Comparison figures and data\n",
    "    \"\"\"\n",
    "    # Extract test returns - ensure it matches the length of kan_weights\n",
    "    test_returns = asset_returns[test_start_idx:test_start_idx + len(kan_weights)]\n",
    "    \n",
    "    # Make sure kan_weights is a numpy array (not JAX array)\n",
    "    kan_weights_np = np.array(kan_weights)\n",
    "    \n",
    "    # 1. Equal Weight\n",
    "    num_assets = asset_returns.shape[1]\n",
    "    equal_weight = np.ones(num_assets) / num_assets\n",
    "    equal_weight_returns = np.sum(equal_weight * test_returns, axis=1)\n",
    "    \n",
    "    # 2. Minimum Variance Portfolio\n",
    "    # Estimate covariance matrix using training data\n",
    "    train_returns = asset_returns[:test_start_idx]\n",
    "    cov_matrix = np.cov(train_returns.T)\n",
    "    \n",
    "    # Setup optimization constraints and bounds\n",
    "    constraints = ({'type': 'eq', 'fun': weight_sum_constraint})\n",
    "    bounds = tuple((0, 1) for _ in range(num_assets))\n",
    "    \n",
    "    # Initial weights (equal weight)\n",
    "    initial_weights = np.ones(num_assets) / num_assets\n",
    "    \n",
    "    # Optimize minimum variance portfolio\n",
    "    min_var_result = minimize(\n",
    "        min_var_objective,\n",
    "        initial_weights, \n",
    "        args=(cov_matrix,),\n",
    "        method='SLSQP',\n",
    "        bounds=bounds, \n",
    "        constraints=constraints\n",
    "    )\n",
    "    \n",
    "    min_var_weights = min_var_result['x']\n",
    "    min_var_returns = np.sum(min_var_weights * test_returns, axis=1)\n",
    "    \n",
    "    # 3. Maximum Sharpe Ratio Portfolio\n",
    "    max_sharpe_result = minimize(\n",
    "        neg_sharpe_ratio, \n",
    "        initial_weights, \n",
    "        args=(train_returns, cov_matrix),\n",
    "        method='SLSQP', \n",
    "        bounds=bounds, \n",
    "        constraints=constraints\n",
    "    )\n",
    "    \n",
    "    max_sharpe_weights = max_sharpe_result['x']\n",
    "    max_sharpe_returns = np.sum(max_sharpe_weights * test_returns, axis=1)\n",
    "    \n",
    "    # 4. Risk Parity Portfolio\n",
    "    risk_parity_result = minimize(\n",
    "        risk_parity_objective, \n",
    "        initial_weights, \n",
    "        args=(cov_matrix,),\n",
    "        method='SLSQP', \n",
    "        bounds=bounds, \n",
    "        constraints=constraints\n",
    "    )\n",
    "    \n",
    "    risk_parity_weights = risk_parity_result['x']\n",
    "    risk_parity_returns = np.sum(risk_parity_weights * test_returns, axis=1)\n",
    "    \n",
    "    # Calculate performance metrics for all portfolios\n",
    "    equal_weight_metrics = calculate_portfolio_metrics(equal_weight_returns)\n",
    "    min_var_metrics = calculate_portfolio_metrics(min_var_returns)\n",
    "    max_sharpe_metrics = calculate_portfolio_metrics(max_sharpe_returns)\n",
    "    risk_parity_metrics = calculate_portfolio_metrics(risk_parity_returns)\n",
    "    \n",
    "    # Calculate KAN portfolio returns\n",
    "    kan_portfolio_returns = np.sum(kan_weights_np * test_returns, axis=1)\n",
    "    \n",
    "    # Create comparison table\n",
    "    methods = ['Equal Weight', 'Min Variance', 'Max Sharpe', 'Risk Parity', 'KAN Portfolio']\n",
    "    metrics_list = [equal_weight_metrics, min_var_metrics, max_sharpe_metrics, risk_parity_metrics, kan_metrics]\n",
    "    \n",
    "    # Extract metrics for comparison\n",
    "    metric_names = ['annual_return', 'annual_volatility', 'sharpe_ratio', 'max_drawdown', 'var_95', 'cvar_95']\n",
    "    comparison_data = {}\n",
    "    \n",
    "    for metric in metric_names:\n",
    "        comparison_data[metric] = [m[metric] for m in metrics_list]\n",
    "    \n",
    "    # Create a figure for comparison\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Format percentages\n",
    "    percentage_metrics = ['annual_return', 'annual_volatility', 'max_drawdown', 'var_95', 'cvar_95']\n",
    "    for metric in percentage_metrics:\n",
    "        comparison_data[metric] = [m * 100 for m in comparison_data[metric]]\n",
    "    \n",
    "    # Plot annual returns\n",
    "    axs[0, 0].bar(methods, comparison_data['annual_return'])\n",
    "    axs[0, 0].set_title('Annual Return (%)')\n",
    "    axs[0, 0].set_ylabel('Return (%)')\n",
    "    axs[0, 0].grid(True, alpha=0.3)\n",
    "    axs[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot annual volatility\n",
    "    axs[0, 1].bar(methods, comparison_data['annual_volatility'])\n",
    "    axs[0, 1].set_title('Annual Volatility (%)')\n",
    "    axs[0, 1].set_ylabel('Volatility (%)')\n",
    "    axs[0, 1].grid(True, alpha=0.3)\n",
    "    axs[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot Sharpe ratio\n",
    "    axs[1, 0].bar(methods, comparison_data['sharpe_ratio'])\n",
    "    axs[1, 0].set_title('Sharpe Ratio')\n",
    "    axs[1, 0].set_ylabel('Sharpe Ratio')\n",
    "    axs[1, 0].grid(True, alpha=0.3)\n",
    "    axs[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot max drawdown\n",
    "    axs[1, 1].bar(methods, comparison_data['max_drawdown'])\n",
    "    axs[1, 1].set_title('Maximum Drawdown (%)')\n",
    "    axs[1, 1].set_ylabel('Drawdown (%)')\n",
    "    axs[1, 1].grid(True, alpha=0.3)\n",
    "    axs[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create a second figure for cumulative returns comparison\n",
    "    fig2, ax2 = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Calculate cumulative returns\n",
    "    equal_weight_cum = np.cumprod(1 + equal_weight_returns) - 1\n",
    "    min_var_cum = np.cumprod(1 + min_var_returns) - 1\n",
    "    max_sharpe_cum = np.cumprod(1 + max_sharpe_returns) - 1\n",
    "    risk_parity_cum = np.cumprod(1 + risk_parity_returns) - 1\n",
    "    kan_cum = np.cumprod(1 + kan_portfolio_returns) - 1\n",
    "    \n",
    "    # Plot cumulative returns\n",
    "    ax2.plot(equal_weight_cum, label='Equal Weight')\n",
    "    ax2.plot(min_var_cum, label='Min Variance')\n",
    "    ax2.plot(max_sharpe_cum, label='Max Sharpe')\n",
    "    ax2.plot(risk_parity_cum, label='Risk Parity')\n",
    "    ax2.plot(kan_cum, label='KAN Portfolio')\n",
    "    \n",
    "    ax2.set_title('Cumulative Returns Comparison')\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('Cumulative Return')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    return fig, fig2, comparison_data\n",
    "\n",
    "# Training functions with fixed JIT compilation issues\n",
    "def train_portfolio_model(model, X_train, y_train, num_epochs=100, batch_size=64,\n",
    "                         loss_type='sharpe', lambda_l2=0.001, lambda_smooth=0.001,\n",
    "                         lambda_turnover=0.001, learning_rate=0.001):\n",
    "    \"\"\"Train the portfolio optimization model.\"\"\"\n",
    "    # Get model parameters and grid points\n",
    "    params = model.params\n",
    "    grid_points = model.layers[0].grid_points  # Assuming all layers use the same grid points\n",
    "    \n",
    "    # JIT-compile the loss function and gradient computation\n",
    "    loss_fn = lambda p, x, y, prev_w: portfolio_loss_fn(\n",
    "        p, model_forward, x, y, grid_points, loss_type, \n",
    "        lambda_l2, lambda_smooth, lambda_turnover, prev_w\n",
    "    )\n",
    "    \n",
    "    value_and_grad_fn = jax.value_and_grad(loss_fn)\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = optax.adam(learning_rate=learning_rate)\n",
    "    opt_state = optimizer.init(params)\n",
    "    \n",
    "    num_samples = X_train.shape[0]\n",
    "    num_batches = num_samples // batch_size\n",
    "    \n",
    "    losses = []\n",
    "    previous_batch_weights = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle data\n",
    "        perm = jax.random.permutation(jax.random.PRNGKey(epoch), num_samples)\n",
    "        X_shuffled = X_train[perm]\n",
    "        y_shuffled = y_train[perm]\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch in range(num_batches):\n",
    "            start_idx = batch * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            \n",
    "            X_batch = X_shuffled[start_idx:end_idx]\n",
    "            y_batch = y_shuffled[start_idx:end_idx]\n",
    "            \n",
    "            # Compute loss and gradients\n",
    "            loss_value, grads = value_and_grad_fn(params, X_batch, y_batch, previous_batch_weights)\n",
    "            \n",
    "            # Update parameters\n",
    "            updates, opt_state = optimizer.update(grads, opt_state)\n",
    "            params = optax.apply_updates(params, updates)\n",
    "            \n",
    "            # Update previous weights for next batch (if using turnover regularization)\n",
    "            if lambda_turnover > 0:\n",
    "                previous_batch_weights = model_forward(params, X_batch, grid_points)\n",
    "            \n",
    "            epoch_loss += loss_value\n",
    "        \n",
    "        epoch_loss /= num_batches\n",
    "        losses.append(epoch_loss)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {epoch_loss:.6f}\")\n",
    "    \n",
    "    # Update model with trained parameters\n",
    "    model.update_params(params)\n",
    "    \n",
    "    return params, losses\n",
    "\n",
    "# Portfolio evaluation functions\n",
    "def evaluate_portfolio(model, params, X_test, y_test, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    Evaluate portfolio performance on test data.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PortfolioKAN model\n",
    "        params: Model parameters\n",
    "        X_test: Test features\n",
    "        y_test: Test returns\n",
    "        risk_free_rate: Risk-free rate\n",
    "        \n",
    "    Returns:\n",
    "        metrics: Performance metrics\n",
    "    \"\"\"\n",
    "    model.update_params(params)\n",
    "    portfolio_weights = model(X_test)\n",
    "    \n",
    "    # Convert to numpy for evaluation\n",
    "    weights_np = np.array(portfolio_weights)\n",
    "    returns_np = np.array(y_test)\n",
    "    \n",
    "    # Calculate portfolio returns\n",
    "    portfolio_returns = np.sum(weights_np * returns_np, axis=1)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    annualization_factor = 252  # Assuming daily returns\n",
    "    \n",
    "    # Mean return\n",
    "    mean_return = np.mean(portfolio_returns)\n",
    "    annual_return = mean_return * annualization_factor\n",
    "    \n",
    "    # Volatility\n",
    "    volatility = np.std(portfolio_returns)\n",
    "    annual_volatility = volatility * np.sqrt(annualization_factor)\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    sharpe_ratio = (annual_return - risk_free_rate) / annual_volatility\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cumulative_returns = np.cumprod(1 + portfolio_returns)\n",
    "    peak = np.maximum.accumulate(cumulative_returns)\n",
    "    drawdown = (peak - cumulative_returns) / peak\n",
    "    max_drawdown = np.max(drawdown)\n",
    "    \n",
    "    # Value at Risk (VaR) at 95% confidence\n",
    "    var_95 = -np.percentile(portfolio_returns, 5)\n",
    "    \n",
    "    # Conditional Value at Risk (CVaR) at 95% confidence\n",
    "    cvar_95 = -np.mean(portfolio_returns[portfolio_returns <= -var_95])\n",
    "    \n",
    "    # Turnover\n",
    "    turnover = np.mean(np.sum(np.abs(weights_np[1:] - weights_np[:-1]), axis=1))\n",
    "    \n",
    "    # Information Ratio vs equal weight benchmark\n",
    "    equal_weight = np.ones_like(weights_np) / weights_np.shape[1]\n",
    "    benchmark_returns = np.sum(equal_weight * returns_np, axis=1)\n",
    "    active_returns = portfolio_returns - benchmark_returns\n",
    "    information_ratio = np.mean(active_returns) / np.std(active_returns) * np.sqrt(annualization_factor)\n",
    "    \n",
    "    # Create metrics dictionary\n",
    "    metrics = {\n",
    "        'annual_return': annual_return,\n",
    "        'annual_volatility': annual_volatility,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'var_95': var_95,\n",
    "        'cvar_95': cvar_95,\n",
    "        'turnover': turnover,\n",
    "        'information_ratio': information_ratio\n",
    "    }\n",
    "    \n",
    "    return metrics, portfolio_returns, portfolio_weights\n",
    "\n",
    "def visualize_portfolio_performance(portfolio_returns, equal_weight_returns, metrics):\n",
    "    \"\"\"\n",
    "    Visualize portfolio performance compared to a benchmark.\n",
    "    \n",
    "    Args:\n",
    "        portfolio_returns: Portfolio returns\n",
    "        equal_weight_returns: Equal weight benchmark returns\n",
    "        metrics: Performance metrics\n",
    "    \"\"\"\n",
    "    # Calculate cumulative returns\n",
    "    portfolio_cum_returns = np.cumprod(1 + portfolio_returns) - 1\n",
    "    benchmark_cum_returns = np.cumprod(1 + equal_weight_returns) - 1\n",
    "    \n",
    "    # Create a figure\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "    # Plot cumulative returns\n",
    "    axs[0].plot(portfolio_cum_returns, 'b-', label='KAN Portfolio')\n",
    "    axs[0].plot(benchmark_cum_returns, 'r--', label='Equal Weight')\n",
    "    axs[0].set_title('Cumulative Returns')\n",
    "    axs[0].set_xlabel('Time')\n",
    "    axs[0].set_ylabel('Cumulative Return')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add performance metrics as a table\n",
    "    metrics_text = f\"\"\"\n",
    "    Annual Return: {metrics['annual_return']:.2%}\n",
    "    Annual Volatility: {metrics['annual_volatility']:.2%}\n",
    "    Sharpe Ratio: {metrics['sharpe_ratio']:.2f}\n",
    "    Maximum Drawdown: {metrics['max_drawdown']:.2%}\n",
    "    95% VaR: {metrics['var_95']:.2%}\n",
    "    95% CVaR: {metrics['cvar_95']:.2%}\n",
    "    Turnover: {metrics['turnover']:.2f}\n",
    "    Information Ratio: {metrics['information_ratio']:.2f}\n",
    "    \"\"\"\n",
    "    \n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    axs[0].text(0.05, 0.05, metrics_text, transform=axs[0].transAxes, fontsize=10,\n",
    "               verticalalignment='bottom', bbox=props)\n",
    "    \n",
    "    # Plot drawdowns\n",
    "    portfolio_peak = np.maximum.accumulate(np.insert(portfolio_cum_returns + 1, 0, 1))\n",
    "    portfolio_drawdown = (portfolio_peak[1:] - (portfolio_cum_returns + 1)) / portfolio_peak[1:]\n",
    "    \n",
    "    benchmark_peak = np.maximum.accumulate(np.insert(benchmark_cum_returns + 1, 0, 1))\n",
    "    benchmark_drawdown = (benchmark_peak[1:] - (benchmark_cum_returns + 1)) / benchmark_peak[1:]\n",
    "    \n",
    "    axs[1].plot(portfolio_drawdown, 'b-', label='KAN Portfolio')\n",
    "    axs[1].plot(benchmark_drawdown, 'r--', label='Equal Weight')\n",
    "    axs[1].set_title('Drawdowns')\n",
    "    axs[1].set_xlabel('Time')\n",
    "    axs[1].set_ylabel('Drawdown')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True, alpha=0.3)\n",
    "    axs[1].invert_yaxis()  # Invert y-axis to show drawdowns as negative\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
